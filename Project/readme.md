<img src="../Docs/earthquake.jpg">

## Problem Satement:
Every year The National Earthquake Information Center (NEIC) records an average of 20,000 earthquakes all around to world. This number is fairly huge, but we can infer from that in order to understand more that is huge, averagely 50 earthquake occured in each day


In 2015 April 25, an intense earthquake occured in Central Nepal at local time of 11:56 a.m. My goal is the predict level of damage of the buildings in 2015 Gorkha earthquake in Nepal. The data that was collected through surveys by Kathmandu Living Labs and the Central Bureau of Statistics will be used in this notebook. This data one of the largest post-disaster dataset ever collected, it includes various information that influence various aspects of science.

Note: The triple dots in the below means there are some hidden codes. It can be opened by clicking on them. This is same for all triple dots in the notebook. (If there is not triple dots or no code hidden, do not consider this note)

## Data Acquisition:

Dataset can be download from kaggle

```
https://www.kaggle.com/datasets/mullerismail/richters-predictor-modeling-earthquake-damage/data
```

## Notebooks

- **[Data-modeling.ipynb](Data-modeling.ipynb)**: This Python script implements Data processing,analysing and train models

## Datasets

In the `Datasets` directory, you will find the following datasets used in the notebooks:

- `train_values.csv`: Dataset for training without labels
- `train_labels.csv`:labels for training data
- `test_values.csv`: testing data without labels

Feel free to explore each notebook and script to understand how different types of data processing tasks.